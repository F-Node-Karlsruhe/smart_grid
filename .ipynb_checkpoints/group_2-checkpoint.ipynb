{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl import KeplerGl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define paths and parameters\n",
    "'''\n",
    "DATA_PATH = './17_18.csv'\n",
    "\n",
    "GEO_DATA_PATH = './country_lat_long.csv'\n",
    "\n",
    "COUNTRIES = ['nl', 'lu', 'fr', 'ch', 'au', 'cz', 'pl', 'dk', 'sw']\n",
    "\n",
    "### Data for 1 Day\n",
    "RESAMPLE_INTERVAL = '1H'\n",
    "TIMESPAN = (pd.Timestamp(2017, 1, 1, 0),pd.Timestamp(2017, 1, 2, 0))\n",
    "\n",
    "### Data for one week\n",
    "#RESAMPLE_INTERVAL = '3H'\n",
    "#TIMESPAN = (pd.Timestamp(2017, 1, 1, 0),pd.Timestamp(2017, 1, 7, 0))\n",
    "\n",
    "### Data for one month\n",
    "#RESAMPLE_INTERVAL = '24H'\n",
    "#TIMESPAN = (pd.Timestamp(2017, 1, 1, 0),pd.Timestamp(2017, 2, 1, 0))\n",
    "\n",
    "### Data for one year\n",
    "#RESAMPLE_INTERVAL = '168H'\n",
    "#TIMESPAN = (pd.Timestamp(2017, 1, 1, 0),pd.Timestamp(2018, 1, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "DATASET = pd.read_csv(DATA_PATH, sep=';')\n",
    "\n",
    "# replace Datum Uhrzeit with proper timestamp as index\n",
    "DATASET['timestamp'] = DATASET.Datum.map(str) + ' ' + DATASET.Uhrzeit\n",
    "DATASET = DATASET.drop(['Uhrzeit', 'Datum'], axis=1)\n",
    "DATASET.set_index('timestamp', inplace=True)\n",
    "# transform to time series\n",
    "DATASET.index = pd.to_datetime(DATASET.index)\n",
    "DATASET = DATASET.apply(pd.to_numeric, errors='coerce')\n",
    "DATASET.fillna(0, inplace=True)\n",
    "\n",
    "# load geo data\n",
    "GEO_DATA = pd.read_csv(GEO_DATA_PATH, sep=';')\n",
    "print(GEO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define data operation functions\n",
    "'''\n",
    "\n",
    "def shrinkIntervalMean(data, interval):\n",
    "    '''\n",
    "    returns the resampled dataset with the mean of the timestamp values in the given interval, \n",
    "    e.g. '10H' for 10 hour intervals\n",
    "    '''\n",
    "    return data.resample(interval).mean()\n",
    "\n",
    "def toKeplerData(dataset, geodata):\n",
    "    '''\n",
    "    returns the given time series with each column as a distinct timestamp \n",
    "    in the series with the specific lat/lang attached\n",
    "    '''\n",
    "    series = pd.DataFrame()\n",
    "    # columns = list(dataset.columns)\n",
    "    for index, row in dataset.iterrows():\n",
    "        for country in COUNTRIES:\n",
    "            geo_ex = geodata.loc[geodata['country'] == country + '_export']\n",
    "            geo_im = geodata.loc[geodata['country'] == country + '_import']\n",
    "            newTimestamp = pd.DataFrame({'value_im':row[country + '_import'],'lat_im':geo_im.iloc[0]['lat'],\n",
    "                                         'long_im':geo_im.iloc[0]['long'],\n",
    "                                        'value_ex':row[country + '_export'],'lat_ex':geo_ex.iloc[0]['lat'],\n",
    "                                         'long_ex':geo_ex.iloc[0]['long']},\n",
    "                                        index=[index])\n",
    "            \n",
    "            series = series.append(newTimestamp)\n",
    "            \n",
    "        net_geo = geodata.loc[geodata['country'] == 'net_export'].iloc[0]\n",
    "        \n",
    "        # Include data for net export\n",
    "        if row['net_export'] > 0:    \n",
    "            series = series.append(pd.DataFrame({'value_im':0,'lat_im':net_geo['lat'],\n",
    "                                         'long_im':net_geo['long'],\n",
    "                                        'value_ex':row['net_export'],'lat_ex':net_geo['lat'],\n",
    "                                         'long_ex':net_geo['long']},\n",
    "                                        index=[index]))\n",
    "        else:\n",
    "            series = series.append(pd.DataFrame({'value_im':row['net_export'],'lat_im':net_geo['lat'],\n",
    "                                         'long_im':net_geo['long'],\n",
    "                                        'value_ex':0,'lat_ex':net_geo['lat'],\n",
    "                                         'long_ex':net_geo['long']},\n",
    "                                        index=[index]))\n",
    "\n",
    "\n",
    "    return series\n",
    "\n",
    "'''\n",
    "Test functions\n",
    "'''\n",
    "#DATASET = shrinkTimeGran(DATASET, '5H')\n",
    "#DATASET = shrinkIntervalMean(DATASET, '8H')\n",
    "#print(toKeplerData(DATASET, GEO_DATA).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data preparation\n",
    "'''\n",
    "\n",
    "# reduce time series granularity to 1 Day\n",
    "DATASET = shrinkIntervalMean(DATASET, RESAMPLE_INTERVAL)\n",
    "series = toKeplerData(DATASET, GEO_DATA)\n",
    "\n",
    "'''\n",
    "Export data to csv\n",
    "'''\n",
    "series.to_csv(r'geo_data_' + RESAMPLE_INTERVAL +'.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import data from csv and transform it for map\n",
    "'''\n",
    "\n",
    "map_data = pd.read_csv('./geo_data_' + RESAMPLE_INTERVAL +'.csv', sep=\",\", parse_dates=[0], index_col=0)[TIMESPAN[0]:TIMESPAN[1]]\n",
    "map_data['time'] = map_data.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "map_data.set_index('time', inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create map\n",
    "'''\n",
    "\n",
    "german_electricity_map = KeplerGl(height=500)\n",
    "german_electricity_map.add_data(data=map_data, name='Strom Im-/Export')\n",
    "german_electricity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save config and save map as html\n",
    "'''\n",
    "\n",
    "map_config = german_electricity_map.config\n",
    "german_electricity_map.save_to_html(file_name='german_electricity_map_' + RESAMPLE_INTERVAL + '.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create new map with same config\n",
    "'''\n",
    "\n",
    "german_electricity_map_2 = KeplerGl(height=500, data={\"Strom Im-/Export\": map_data}, config=map_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
